alist( height ~ dnorm( mu , sigma ) ,
mu <- a + b1*weight_s + b2*weight_s2 ,
a ~ dnorm( 178 , 20 ) ,
b1 ~ dlnorm( 0 , 1 ) ,
b2 ~ dnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 50 )
) , data=d )
set.seed(45)
prior <- extract.prior( m4.5 )
precis( prior )
?extract.prior
post <- extract.samples( m4.5 )
precis( post )
w_seq <- seq( from=min(d$weight_s) , to=max(d$weight_s) , length.out=50 )
w2_seq <- w_seq^2
mu <- link( m4.5 , post=prior ,
data=list( weight_s=w_seq , weight_s2=w2_seq ) )
plot( NULL , xlim=range(w_seq) , ylim=c(55,270) , xlab="weight (std)" , ylab="height" )
for ( i in 1:50 ) lines( w_seq , mu[i,] , col=col.alpha("black",0.5) )
?link
library(rethinking)
library(splines)
tot <- read.csv("data2/tot_fail.csv")
normalize <- function(x) {
return ((x - mean(x)) / (sd(x)))
}
tot_age_max = mean(tot$avg)
tot_age_min = sd(tot$avg)
tot$avg = normalize(tot$avg)
num_knots <- 15
knot_list <- quantile(tot$age, probs = seq(0,1,length.out = num_knots))
B <- bs(tot$age,knots=knot_list , degree=3 , intercept=TRUE )
plot( NULL , xlim=range(tot$age) , ylim=c(0,1) , xlab="age" , ylab="failure count" )
for ( i in 1:ncol(B) ) lines(tot$age , B[,i] )
lm(tot$avg ~ tot$age)
tot <- read.csv("data2/tot_fail.csv")
e1 <- read.csv("data2/0101_fail.csv")
e2 <- read.csv("data2/0102_fail.csv")
e3 <- read.csv("data2/0202_fail.csv")
e4 <- read.csv("data2/0204_fail.csv")
e5 <- read.csv("data2/0602_fail.csv")
hist(tot$avg, nclass = 10)
hist(e1$avg, nclass = 6)
hist(e2$avg, nclass = 6)
hist(e3$avg, nclass = 6)
hist(e4$avg, nclass = 6)
hist(e5$avg, nclass = 6)
library(rethinking)
library(splines)
tot <- read.csv("data2/tot_fail.csv")
normalize <- function(x) {
return ((x - mean(x)) / (sd(x)))
}
tot_age_max = mean(tot$avg)
tot_age_min = sd(tot$avg)
tot$avg = normalize(tot$avg)
num_knots <- 15
knot_list <- quantile(tot$age, probs = seq(0,1,length.out = num_knots))
B <- bs(tot$age,knots=knot_list , degree=3 , intercept=TRUE )
plot( NULL , xlim=range(tot$age) , ylim=c(0,1) , xlab="age" , ylab="failure count" )
for ( i in 1:ncol(B) ) lines(tot$age , B[,i] )
lm(tot$avg ~ tot$age)
layer1 <- quap(
alist( T ~ dnorm( mu , sigma ) ,
mu <- a + B %*% w ,
a ~ dnorm(-0.89, 10), w ~ dnorm(0,1), sigma ~ dexp(1)
),
data=list( T=tot$avg , B=B ) ,
start=list( w=rep( 0 , ncol(B) ) ) )
post <- extract.samples(layer1)
w <- apply( post$w , 2 , mean )
plot( NULL , xlim=range(data$age) , ylim=c(-2,2) ,xlab="year" , ylab="basis * weight" )
normalize <- function(x) {
return ((x - mean(x)) / (sd(x)))
}
tot_age_max = mean(tot$avg)
tot_age_min = sd(tot$avg)
tot$avg = normalize(tot$avg)
num_knots <- 15
knot_list <- quantile(tot$age, probs = seq(0,1,length.out = num_knots))
B <- bs(tot$age,knots=knot_list , degree=3 , intercept=TRUE )
plot( NULL , xlim=range(tot$age) , ylim=c(0,1) , xlab="age" , ylab="failure count" )
for ( i in 1:ncol(B) ) lines(tot$age , B[,i] )
# w평균은 보통 0으로? alpha, w에 대한 표준편차 부분 조정하며 prior predictive dist 검토 필요(교과서 11장 참조)
data_list<- list(
nships <- 99,
engine <- as.integer(se$engine))
data_list<- list(
nships <- 99,
engine <- as.integer(se$engine))
se
se
library(rethinking)
library(splines)
tot <- read.csv("data2/tot_fail.csv")
normalize <- function(x) {
return ((x - mean(x)) / (sd(x)))
}
tot_age_max = mean(tot$avg)
tot_age_min = sd(tot$avg)
tot$avg = normalize(tot$avg)
num_knots <- 15
knot_list <- quantile(tot$age, probs = seq(0,1,length.out = num_knots))
B <- bs(tot$age,knots=knot_list , degree=3 , intercept=TRUE )
plot( NULL , xlim=range(tot$age) , ylim=c(0,1) , xlab="age" , ylab="failure count" )
for ( i in 1:ncol(B) ) lines(tot$age , B[,i] )
lm(tot$avg ~ tot$age)
layer1 <- quap(
alist( T ~ dnorm( mu , sigma ) ,
mu <- a + B %*% w ,
a ~ dnorm(-0.89, 10), w ~ dnorm(0,1), sigma ~ dexp(1)
),
data=list( T=tot$avg , B=B ) ,
start=list( w=rep( 0 , ncol(B) ) ) )
post <- extract.samples(layer1)
w <- apply( post$w , 2 , mean )
plot( NULL , xlim=range(data$age) , ylim=c(-2,2) ,xlab="year" , ylab="basis * weight" )
library(rethinking)
library(splines)
tot <- read.csv("data2/tot_fail.csv")
normalize <- function(x) {
return ((x - mean(x)) / (sd(x)))
}
tot_age_max = mean(tot$avg)
tot_age_min = sd(tot$avg)
tot$avg = normalize(tot$avg)
num_knots <- 15
knot_list <- quantile(tot$age, probs = seq(0,1,length.out = num_knots))
B <- bs(tot$age,knots=knot_list , degree=3 , intercept=TRUE )
plot( NULL , xlim=range(tot$age) , ylim=c(0,1) , xlab="age" , ylab="failure count" )
for ( i in 1:ncol(B) ) lines(tot$age , B[,i] )
lm(tot$avg ~ tot$age)
layer1 <- quap(
alist( T ~ dnorm( mu , sigma ) ,
mu <- a + B %*% w ,
a ~ dnorm(-0.89, 10), w ~ dnorm(0,1), sigma ~ dexp(1)
),
data=list( T=tot$avg , B=B ) ,
start=list( w=rep( 0 , ncol(B) ) ) )
post <- extract.samples(layer1)
w <- apply( post$w , 2 , mean )
for ( i in 1:ncol(B) ) lines( data$age , w[i]*B[,i] )
library(rethinking)
library(splines)
tot <- read.csv("data2/tot_fail.csv")
normalize <- function(x) {
return ((x - mean(x)) / (sd(x)))
}
tot_age_max = mean(tot$avg)
tot_age_min = sd(tot$avg)
tot$avg = normalize(tot$avg)
num_knots <- 15
knot_list <- quantile(tot$age, probs = seq(0,1,length.out = num_knots))
B <- bs(tot$age,knots=knot_list , degree=3 , intercept=TRUE )
plot( NULL , xlim=range(tot$age) , ylim=c(0,1) , xlab="age" , ylab="failure count" )
for ( i in 1:ncol(B) ) lines(tot$age , B[,i] )
lm(tot$avg ~ tot$age)
layer1 <- quap(
alist( T ~ dnorm( mu , sigma ) ,
mu <- a + B %*% w ,
a ~ dnorm(-0.89, 10), w ~ dnorm(0,1), sigma ~ dexp(1)
),
data=list( T=tot$avg , B=B ) ,
start=list( w=rep( 0 , ncol(B) ) ) )
post <- extract.samples(layer1)
w <- apply( post$w , 2 , mean )
w
a <- apply( post$w , 2 , mean )
a
a <- apply( post$a , 2 , mean )
a <- apply( post$a , mean )
post
mean(post$a)
tot
w <- apply( post$w , 2 , mean )
w
tot <- read.csv("data2/tot.csv")
tot <- read.csv("data2/tot_fail.csv")
library(rethinking)
library(splines)
#tot <- read.csv("data2/tot_fail.csv")
tot <- read.csv("data2/tot.csv")
normalize <- function(x) {
return ((x - mean(x)) / (sd(x)))
}
tot_age_max = mean(tot$avg)
tot_age_min = sd(tot$avg)
tot$avg = normalize(tot$avg)
num_knots <- 15
knot_list <- quantile(tot$age, probs = seq(0,1,length.out = num_knots))
B <- bs(tot$age,knots=knot_list , degree=3 , intercept=TRUE )
plot( NULL , xlim=range(tot$age) , ylim=c(0,1) , xlab="age" , ylab="failure count" )
for ( i in 1:ncol(B) ) lines(tot$age , B[,i] )
lm(tot$avg ~ tot$age)
layer1 <- quap(
alist( T ~ dnorm( mu , sigma ) ,
mu <- a + B %*% w ,
a ~ dnorm(-0.89, 10), w ~ dnorm(0,1), sigma ~ dexp(1)
),
data=list( T=tot$avg , B=B ) ,
start=list( w=rep( 0 , ncol(B) ) ) )
post <- extract.samples(layer1)
w <- apply( post$w , 2 , mean )
a <- mean(post$a)
library(rethinking)
library(splines)
#tot <- read.csv("data2/tot_fail.csv")
tot <- read.csv("data2/tot.csv")
normalize <- function(x) {
return ((x - mean(x)) / (sd(x)))
}
tot_age_max = mean(tot$avg)
tot_age_min = sd(tot$avg)
tot$avg = normalize(tot$avg)
num_knots <- 15
knot_list <- quantile(tot$age, probs = seq(0,1,length.out = num_knots))
B <- bs(tot$age,knots=knot_list , degree=3 , intercept=TRUE )
plot( NULL , xlim=range(tot$age) , ylim=c(0,1) , xlab="age" , ylab="failure count" )
for ( i in 1:ncol(B) ) lines(tot$age , B[,i] )
lm(tot$avg ~ tot$age)
layer1 <- quap(
alist( T ~ dnorm( mu , sigma ) ,
mu <- a + B %*% w ,
a ~ dnorm(-0.89, 10), w ~ dnorm(0,1), sigma ~ dexp(1)
),
data=list( T=tot$avg , B=B ) ,
start=list( w=rep( 0 , ncol(B) ) ) )
post <- extract.samples(layer1)
w <- apply( post$w , 2 , mean )
a <- mean(post$a)
w <- apply( post$w , 2 , mean )
w
a
B
library(rethinking)
library(splines)
#tot <- read.csv("data2/tot_fail.csv")
tot <- read.csv("data2/tot.csv")
normalize <- function(x) {
return ((x - mean(x)) / (sd(x)))
}
tot_age_max = mean(tot$avg)
tot_age_min = sd(tot$avg)
tot$avg = normalize(tot$avg)
num_knots <- 15
knot_list <- quantile(tot$age, probs = seq(0,1,length.out = num_knots))
B <- bs(tot$age,knots=knot_list , degree=3 , intercept=TRUE )
plot( NULL , xlim=range(tot$age) , ylim=c(0,1) , xlab="age" , ylab="failure count" )
for ( i in 1:ncol(B) ) lines(tot$age , B[,i] )
lm(tot$avg ~ tot$age)
layer1 <- quap(
alist( T ~ dnorm( mu , sigma ) ,
mu <- a + B %*% w ,
a ~ dnorm(-0.89, 10), w ~ dnorm(0,1), sigma ~ dexp(1)
),
data=list( T=tot$avg , B=B ) ,
start=list( w=rep( 0 , ncol(B) ) ) )
post <- extract.samples(layer1)
w <- apply( post$w , 2 , mean )
a <- mean(post$a)
library(rethinking)
library(splines)
tot <- read.csv("data2/tot.csv")
normalize <- function(x) {
return ((x - mean(x)) / (sd(x)))
}
tot_age_max = mean(tot$avg)
tot_age_min = sd(tot$avg)
tot$avg = normalize(tot$avg)
num_knots <- 15
knot_list <- quantile(tot$age, probs = seq(0,1,length.out = num_knots))
B <- bs(tot$age,knots=knot_list , degree=3 , intercept=TRUE )
plot( NULL , xlim=range(tot$age) , ylim=c(0,1) , xlab="age" , ylab="failure count" )
for ( i in 1:ncol(B) ) lines(tot$age , B[,i] )
lm(tot$avg ~ tot$age)
layer1 <- quap(
alist( T ~ dnorm( mu , sigma ) ,
mu <- a + B %*% w ,
a ~ dnorm(-0.89, 10), w ~ dnorm(0,1), sigma ~ dexp(1)
),
data=list( T=tot$avg , B=B ) ,
start=list( w=rep( 0 , ncol(B) ) ) )
post <- extract.samples(layer1)
w <- apply( post$w , 2 , mean )
a <- mean(post$a)
print(w, a)
a
library(rethinking)
library(splines)
tot <- read.csv("data2/tot.csv")
normalize <- function(x) {
return ((x - mean(x)) / (sd(x)))
}
tot_age_max = mean(tot$avg)
tot_age_min = sd(tot$avg)
tot$avg = normalize(tot$avg)
num_knots <- 15
knot_list <- quantile(tot$age, probs = seq(0,1,length.out = num_knots))
B <- bs(tot$age,knots=knot_list , degree=3 , intercept=TRUE )
plot( NULL , xlim=range(tot$age) , ylim=c(0,1) , xlab="age" , ylab="failure count" )
for ( i in 1:ncol(B) ) lines(tot$age , B[,i] )
lm(tot$avg ~ tot$age)
layer1 <- quap(
alist( T ~ dnorm( mu , sigma ) ,
mu <- a + B %*% w ,
a ~ dnorm(-0.89, 10), w ~ dnorm(0,1), sigma ~ dexp(1)
),
data=list( T=tot$avg , B=B ) ,
start=list( w=rep( 0 , ncol(B) ) ) )
post <- extract.samples(layer1)
w <- apply( post$w , 2 , mean )
a <- mean(post$a)
print(w)
print(a)
library(rethinking)
library(ggplot2, reshape2)
data(Howell1)
d <- Howell1
# 주어진 몸무게가 모두 어른 몸무게이므로, 18이상으로 필터링
d2 <- d[d$age >= 18,]
data("foxes")
?scale
data("foxes")
d <- foxes
d$w <- standardize(d$weight)
d$A <- standardize(d$age)
data("foxes")
d <- foxes
d$w <- standardize(d$weight)
d$A <- standardize(d$area)
m1 <- quap(
alist(
W ~ dnorm(mu, sigma),
mu <- a + bA * A,
a ~ dnorm(0, 0.2),
b ~ dnorm(0, 0.5),
sigma ~ dexp(1)
), data = d)
data("foxes")
d <- foxes
d$w <- standardize(d$weight)
d$A <- standardize(d$area)
m1 <- quap(
alist(
W ~ dnorm(mu, sigma),
mu <- a + bA * A,
a ~ dnorm(0, 0.2),
b ~ dnorm(0, 0.5),
sigma ~ dexp(1)
), data = d)
data("foxes")
d <- foxes
d$W <- standardize(d$weight)
d$A <- standardize(d$area)
m1 <- quap(
alist(
W ~ dnorm(mu, sigma),
mu <- a + bA * A,
a ~ dnorm(0, 0.2),
b ~ dnorm(0, 0.5),
sigma ~ dexp(1)
), data = d)
data("foxes")
d <- foxes
d$W <- standardize(d$weight)
d$A <- standardize(d$area)
m1 <- quap(
alist(
W ~ dnorm(mu, sigma),
mu <- a + bA * A,
a ~ dnorm(0, 0.2),
bA ~ dnorm(0, 0.5),
sigma ~ dexp(1)
), data = d)
premis(m1)
data("foxes")
d <- foxes
d$W <- standardize(d$weight)
d$A <- standardize(d$area)
m1 <- quap(
alist(
W ~ dnorm(mu, sigma),
mu <- a + bA * A,
a ~ dnorm(0, 0.2),
bA ~ dnorm(0, 0.5),
sigma ~ dexp(1)
), data = d)
precis(m1)
d$F <- standardize(d$avgfood)
m2 <- quap(
alist(
W ~ dnorm(mu, sigma),
mu <- a + bF * F,
a ~ dnorm(0, 0.2),
b ~ dnorm(0, 0.5),
sigma ~ dexp(1)
), data = d)
d$F <- standardize(d$avgfood)
m2 <- quap(
alist(
W ~ dnorm(mu, sigma),
mu <- a + bF * F,
a ~ dnorm(0, 0.2),
bF ~ dnorm(0, 0.5),
sigma ~ dexp(1)
), data = d)
precis(m2)
d$G <- standardize(d$groupsize)
m3 <- quap(
alist(
W ~ dnorm(mu, sigma),
mu <- a + bF * F + bG * G,
a ~ dnonrm(0, 0.2),
c(bF, bG) ~ dnorm(0, 0.5),
sigma ~ dexp(1)
), data = d)
d$G <- standardize(d$groupsize)
m3 <- quap(
alist(
W ~ dnorm(mu, sigma),
mu <- a + bF * F + bG * G,
a ~ dnorm(0, 0.2),
c(bF, bG) ~ dnorm(0, 0.5),
sigma ~ dexp(1)
), data = d)
precis(m3)
H <- function(p) -sum(p*log(p))
H <- function(p) -sum(p*log(p))
IB <- list()
IB[[1]] <- c( 0.2 , 0.2 , 0.2 , 0.2 , 0.2 )
IB[[2]] <- c( 0.8 , 0.1 , 0.05 , 0.025 , 0.025 )
IB[[3]] <- c( 0.05 , 0.15 , 0.7 , 0.05 , 0.05 )
sapply( IB , H )
Dm
H <- function(p) -sum(p*log(p))
IB <- list()
IB[[1]] <- c( 0.2 , 0.2 , 0.2 , 0.2 , 0.2 )
IB[[2]] <- c( 0.8 , 0.1 , 0.05 , 0.025 , 0.025 )
IB[[3]] <- c( 0.05 , 0.15 , 0.7 , 0.05 , 0.05 )
sapply( IB , H )
DKL <- function(p,q) sum( p*(log(p)-log(q)) )
#1.6094379 0.7430039 0.9836003 분포분균일 첫 섬이 최대 엔트로피 / DKL은 p가 참, q가 모델일 때 두 분포간 거리
#다음은 이를 3 * 3 행렬로 표현
Dm <- matrix( NA , nrow=3 , ncol=3 ) for ( i in 1:3 ) for ( j in 1:3 ) Dm[i,j] <- DKL( IB[[j]] , IB[[i]] ) round( Dm , 2 )
for ( i in 1:3 ) for ( j in 1:3 ) Dm[i,j] <- DKL( IB[[j]] , IB[[i]] ) round( Dm , 2 )
H <- function(p) -sum(p*log(p))
IB <- list()
IB[[1]] <- c( 0.2 , 0.2 , 0.2 , 0.2 , 0.2 )
IB[[2]] <- c( 0.8 , 0.1 , 0.05 , 0.025 , 0.025 )
IB[[3]] <- c( 0.05 , 0.15 , 0.7 , 0.05 , 0.05 )
sapply( IB , H )
DKL <- function(p,q) sum( p*(log(p)-log(q)) )
#1.6094379 0.7430039 0.9836003 분포분균일 첫 섬이 최대 엔트로피 / DKL은 p가 참, q가 모델일 때 두 분포간 거리
#다음은 이를 3 * 3 행렬로 표현
Dm <- matrix( NA , nrow=3 , ncol=3 )
for ( i in 1:3 ) for ( j in 1:3 ) Dm[i,j] <- DKL( IB[[j]] , IB[[i]] )
round( Dm , 2 )
Dm
H <- function(p) -sum(p*log(p))
IB <- list()
IB[[1]] <- c( 0.2 , 0.2 , 0.2 , 0.2 , 0.2 )
IB[[2]] <- c( 0.8 , 0.1 , 0.05 , 0.025 , 0.025 )
IB[[3]] <- c( 0.05 , 0.15 , 0.7 , 0.05 , 0.05 )
sapply( IB , H )
DKL <- function(p,q) sum( p*(log(p)-log(q)) )
#1.6094379 0.7430039 0.9836003 분포분균일 첫 섬이 최대 엔트로피 / DKL은 p가 참, q가 모델일 때 두 분포간 거리
#다음은 이를 3 * 3 행렬로 표현
Dm <- matrix( NA , nrow=3 , ncol=3 )
for ( i in 1:3 ) for ( j in 1:3 ) Dm[i,j] <- DKL( IB[[j]] , IB[[i]] )
round( Dm , 2 )
d <- sim_happiness( seed=1977 , N_years=1000 )
precis(d)
d2 <- d[ d$age>17 , ] # only adults
d2$A <- ( d2$age - 18 ) / ( 65 - 18 )
d2$mid <- d2$married + 1
m6.9 <- quap(
alist(
happiness ~ dnorm( mu , sigma ),
mu <- a[mid] + bA*A,
a[mid] ~ dnorm( 0 , 1 ),
bA ~ dnorm( 0 , 2 ),
sigma ~ dexp(1)
) , data=d2 )
precis(m6.9,depth=2)
m6.10 <- quap(
alist(
happiness ~ dnorm( mu , sigma ),
mu <- a + bA*A,
a ~ dnorm( 0 , 1 ),
bA ~ dnorm( 0 , 2 ),
sigma ~ dexp(1)
) , data=d2 )
precis(m6.10)
compare(m6.9,m6.10 )
plot(asin(seq(0,1,10)))
seq(0,1,10)
?seq()
?seq
seq(0, 1, length.out = 10)
plot(asin(seq(0, 1, length.out = 10)))
par (mfrow=c(5,4), mar=c(4,4,2,2))
par()
?par
hmc
setwd("~/Dropbox/stan/casestudy/lotka-volterra")
lynx_hare_df <-
read.csv("hudson-bay-lynx-hare.csv",
comment.char="#")
N <- length(lynx_hare_df$Year) - 1
N
lynx_hare_df[2:]
lynx_hare_df[2:(N + 1), 2:3]
